---
title: "Quick Start"
description: "Quick start of Pathway AI Pipelines"
navigation: true
heading: false
toc: false
---

# Quick Start

The Pathway AI Pipelines provide a ready-to-use setup for creating real-time, AI-driven applications. With YAML-configured templates, it's easy to customize or create your own processing pipelines for use cases like document indexing, real-time knowledge mining, and alerting.

This quick start guide will help you set up and run Pathway's AI Pipelines, a powerful framework for building real-time, AI-driven applications using large language models (LLMs). Whether you’re developing a document indexing solution, a knowledge mining system, or a query-response interface, this guide will get you started quickly.

## Prerequisites

To get started, you'll need:
- Git to clone the repository and manage updates
- LLM API Key (e.g., OpenAI or Hugging Face) for embedding and querying models

**Running Options**
1. Docker (recommended) will install all dependencies automatically
2. Python 3.8+ with [Pathway](/developers/user-guide/introduction/installation) if you prefer a local setup.

**Note**: if you are using Pathway locally, you will need to install Pathway LLM xpack:
```
pip install pathway[all]
```

**Optional**: Install Streamlit for UI and pip for dependency management (if not using Docker).


## Clone the Repository

First, you need to download the repository.

```
git clone https://github.com/pathwaycom/llm-app.git
```


## Selecting Your Template

Pathway AI Pipelines provide several ready-to-go templates for common use cases.
Whether you need a real-time alerting system, document indexing, or context-based Q&A, you’ll find templates for each.
If none match your needs exactly, the framework provides all the necessary tools to [create your own pipeline](/developers/ai-pipelines/create-your-own).

::container{.flex .gap-8 .items-center .w-full .justify-center}
    ::pathway-button{icon="uil:github" type="secondary" href="/developers/templates#llm"}
    See the templates.
    ::
::

Then you need to go the repository of the chosen template, let's take the `demo-question-answering` as an example.

```
cd llm-app/examples/pipelines/demo-question-answering
```

## Configuring and Running Pathway AI Pipelines

Most of the templates can be configured using a YAML file.
You can learn how to configure them by reading the [dedicated tutorial](/developers/ai-pipelines/configure-yaml).

You can run Pathway AI Pipelines either locally or using Docker.
With Docker, setup is automated, handling all required dependencies.
For a local setup, you’ll install dependencies manually using Python and Pathway.
For detailed configuration and usage steps, refer to the README and articles included with each template.
